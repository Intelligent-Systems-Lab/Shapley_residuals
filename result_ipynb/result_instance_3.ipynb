{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:04.977523Z",
     "iopub.status.busy": "2024-05-10T05:48:04.977432Z",
     "iopub.status.idle": "2024-05-10T05:48:06.054708Z",
     "shell.execute_reply": "2024-05-10T05:48:06.054453Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import bisect\n",
    "import math\n",
    "import json\n",
    "class Hypercube:                #超立方體\n",
    "    '''\n",
    "    A class to create a hypercube object which stores values on vertices\n",
    "    and values on the edges between neighboring vertices\n",
    "    '''    \n",
    "    #輸入維度、(點鍵值)、(點值)\n",
    "    def __init__(self, n_vertices, vertex_keys = None, vertex_values = None):   \n",
    "        self.n_vertices = n_vertices\n",
    "        self.v_num = 2**self.n_vertices\n",
    "        self.V = [np.array([])] + all_subsets(n_vertices)   #所有子集包含空集，即所有點\n",
    "        self.V_value = {str(v) : 0. for v in self.V}         #所有點值  先設為0\n",
    "        self.E = []\n",
    "        self.E_value = {}\n",
    "        self.partial_gradient = {vertex : {} for vertex in range(n_vertices)}   #各個維度的partial gradient\n",
    "        self.matrix = np.full((self.v_num,self.v_num),np.nan)                   #原始立方體對應到的矩陣\n",
    "        self.partial_gradient_matrix = np.full((self.v_num,self.v_num),np.nan)  #對特定 feature的partial gradient\n",
    "        self.vi_matrix = np.full((self.v_num,self.v_num),np.nan)                #v_i對應到的矩陣\n",
    "        self.res_matrix = np.full((self.v_num,self.v_num),np.nan)               #residual的matrix\n",
    "        self.sv = 0\n",
    " \n",
    "    def set_vertex_values(self, vertex_values):         #設置點值\n",
    "        for v in vertex_values:                         #用鍵值來做查找\n",
    "            self.V_value[v] = vertex_values[v]\n",
    "            \n",
    "        # edge values are the differences between neighboring vertex values\n",
    "        #self._calculate_edges()\n",
    "        \n",
    "    def _calculate_edges(self):                 #計算邊值\n",
    "        \n",
    "        # calculate the usual gradients: the difference between neighboring edges\n",
    "        for i, v in enumerate(self.V):\n",
    "            for _v in self.V[i+1:]:\n",
    "                if self._vertices_form_a_valid_edge(v, _v):\n",
    "                    self.E.append((v, _v))\n",
    "                    self.E_value[str((v, _v))] = self.V_value[str(_v)] - self.V_value[str(v)]\n",
    "        \n",
    "        # calculate partial gradients\n",
    "        for vertex in range(self.n_vertices):\n",
    "            self.partial_gradient[vertex] = self.E_value.copy()\n",
    "            for v, _v in self.E:\n",
    "                is_relevant_edge_for_partial_gradient = (vertex in v and vertex not in _v) or (vertex in _v and vertex not in v)\n",
    "                if not is_relevant_edge_for_partial_gradient:\n",
    "                    self.partial_gradient[vertex][str((v, _v))] = 0.\n",
    "            \n",
    "    def _vertices_form_a_valid_edge(self, v, _v):       #檢查交集和是否相鄰\n",
    "        # vertices are neighbors in a hypercube\n",
    "        # if they differ by exactly one element\n",
    "        differ_in_size_by_1 = (abs(len(v) - len(_v)) == 1)      #差距是1\n",
    "    \n",
    "        the_intersection = np.intersect1d(v, _v)                #兩個集合的交集\n",
    "        #print(type(v[0]),type(_v[0]),type(the_intersection[0]))\n",
    "        intersection_is_nonempty = len(the_intersection) > 0 or len(v)==0 or len(_v) == 0   #交集大於0或v,_v是空集\n",
    "        is_intersection = False                         \n",
    "        if len(the_intersection)>0:                              \n",
    "            if len(the_intersection)==len(v) or len(the_intersection)==len(_v):\n",
    "                is_intersection = True\n",
    "        else:\n",
    "            if len(v)==0 and len(_v)==1:\n",
    "                is_intersection = True\n",
    "       # print(is_intersection)\n",
    "        return differ_in_size_by_1 and intersection_is_nonempty and is_intersection\n",
    "    \n",
    "    #create matrix for Hypercube\n",
    "    def trans_to_matrix(self,feature_i):                #超立方體轉換成矩陣\n",
    "        for i, v in enumerate(self.V):                  #對立方體上所有點\n",
    "            for j,_v in enumerate(self.V[i+1:]):        \n",
    "                if self._vertices_form_a_valid_edge(v, _v):     #是否相交\n",
    "                    self.matrix[i][i+j+1] = self.V_value[str(_v)] - self.V_value[str(v)]    #獲得matrix\n",
    "                    self.matrix[i+j+1][i] = self.V_value[str(v)] - self.V_value[str(_v)]\n",
    "        \n",
    "            \n",
    "        self.partial_gradient_matrix = self.matrix.copy()       #把原始立方體複製下來，保留i方向\n",
    "        self.my_list = []\n",
    "        self.partial_gradient_vector = np.array([])\n",
    "        self.weight_vector = np.array([])\n",
    "        self.partial_gradient_norm = 0\n",
    "        for j, v in enumerate(self.V):\n",
    "            for k,_v in enumerate(self.V[j+1:]):\n",
    "                if self._vertices_form_a_valid_edge(v, _v):     #如果是邊\n",
    "                    is_relevant_edge_for_partial_gradient = (feature_i in v and feature_i not in _v) or (feature_i in _v and feature_i not in v)\n",
    "                    if not is_relevant_edge_for_partial_gradient:           #如果 特徵i不在v 或_v，把那條邊設成0\n",
    "                        self.partial_gradient_matrix[j][j+k+1] = 0.\n",
    "                        self.partial_gradient_matrix[j+k+1][j] = 0.\n",
    "                    else:\n",
    "                        self.partial_gradient_norm += (self.partial_gradient_matrix[j][j+k+1])**2       # norm\n",
    "                        self.partial_gradient_vector = np.append(self.partial_gradient_vector,self.partial_gradient_matrix[j][j+k+1])      #比較向量1\n",
    "                        subset_len = len(v)\n",
    "                        weight = 1./(math.comb(self.n_vertices,subset_len)*(self.n_vertices-subset_len))            #Shapley value權重參數\n",
    "                        self.weight_vector = np.append(self.weight_vector,weight)\n",
    "                        self.my_list.append((j,j+k+1))          \n",
    "        #self.vi[feature_i] = self.shapley_residuals_in_matrix()\n",
    "        #self.vi[i] = self.shapley_residuals_in_matrix\n",
    "    #minimize the function (gradient_x - partial_gradient_i)^2 最小化l2_norm\n",
    "    def shapley_residuals_in_matrix(self):\n",
    "            derivative_i  = np.full((self.v_num,self.v_num),0.)      #計算微分後得到的方程式矩陣 A\n",
    "            b_i = np.array([0.]*self.v_num)                          #得到Ax = b 的 b向量值\n",
    "            for j  in range(self.v_num):                            #對矩陣的每個點\n",
    "                for k in range(self.v_num):\n",
    "                    if np.isnan(self.partial_gradient_matrix[j][k]):    #不用計算nan\n",
    "                        continue\n",
    "                    #elif j == 0 or k ==0:                               #如果是跟原點相鄰\n",
    "                     #   derivative_i[j][j] += 1.                       #係數+1\n",
    "                      #  b_i[j] += - self.partial_gradient_matrix[j][k]     #x_j-x_i-partial_gradient\n",
    "                    else:                                               \n",
    "                        derivative_i[j][j] += 1.                         \n",
    "                        derivative_i[j][k] += -1.\n",
    "                        b_i[j] += - self.partial_gradient_matrix[j][k]\n",
    "            A = derivative_i[1:,1:]                                    #只要x_i for i!=0\n",
    "            \n",
    "            B = b_i[1:]                                                #保留b_i\n",
    "            res = 0.\n",
    "            A_inverse = np.linalg.inv(A)                               #算inverse matrix\n",
    "            vi = np.insert(np.dot(A_inverse,B),0,0.)                    #vi  = b/A #開頭補0\n",
    "            vi_V =  [np.array([])] + all_subsets(self.n_vertices)\n",
    "            vi_V_value = {str(v) : 0. for v in vi_V} \n",
    "            res_dic = {}\n",
    "            for k,v in enumerate(vi_V):               \n",
    "                vi_V_value[str(v)] = vi[k]\n",
    "            self.vi_vector = np.array([])                              #比較向量#2\n",
    "            for i, v in enumerate(vi_V):\n",
    "                for j,_v in enumerate(vi_V[i+1:]):\n",
    "                    if self._vertices_form_a_valid_edge(v, _v):\n",
    "                        self.vi_matrix[i][i+j+1] = vi_V_value[str(_v)] - vi_V_value[str(v)]\n",
    "                        self.vi_matrix[i+j+1][i] = vi_V_value[str(v)] - vi_V_value[str(_v)]\n",
    "                        self.res_matrix[i][i+j+1] = self.partial_gradient_matrix[i][i+j+1] - self.vi_matrix[i][i+j+1]\n",
    "                        self.res_matrix[i+j+1][i] = self.partial_gradient_matrix[i+j+1][i] - self.vi_matrix[i+j+1][i]\n",
    "                        res += (self.res_matrix[i][i+j+1])**2\n",
    "                        res_dic[str(v)+'->'+str(_v)] = self.res_matrix[i][i+j+1]\n",
    "                        if (i,i+j+1) in self.my_list:\n",
    "                            self.vi_vector = np.append(self.vi_vector,self.vi_matrix[i][i+j+1])     #比較向量#2\n",
    "            #print(self.my_list)\n",
    "            #print(self.partial_gradient_vector,self.vi_vector)\n",
    "            vector_A = self.weight_vector*self.partial_gradient_vector\n",
    "            vector_B = self.weight_vector*self.vi_vector\n",
    "            cos_sim = self.cos_sim(vector_A,vector_B)\n",
    "            print('cos_sim = ',cos_sim)\n",
    "            self.sv += vi[-1]\n",
    "            print('shapley_value: ',vi[-1],'residual sum: ',res)\n",
    "            #print(self.sv)\n",
    "            #print('residuals_sum:',res,'shapley_value: ',vi)\n",
    "            res =  (res/self.partial_gradient_norm)**0.5\n",
    "            print('norm: ',res)\n",
    "            \n",
    "            return vi_V_value, res_dic, self.partial_gradient_norm\n",
    "    \n",
    "    def cos_sim(self,a,b):\n",
    "        dot_product = np.dot(a, b)\n",
    "        norm_a = np.linalg.norm(a)\n",
    "        norm_b = np.linalg.norm(b)\n",
    "        similarity = dot_product / (norm_a * norm_b)\n",
    "        return similarity\n",
    "            \n",
    "####################     \n",
    "def save_json(dic,feature_name):\n",
    "    filename = f\"dic_{feature_name}.json\"\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(dic, json_file)\n",
    "\n",
    "def save_res_json(dic,feature_name):\n",
    "    filename = f\"dic_{feature_name}_res.json\"\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(dic, json_file)\n",
    "\n",
    "        \n",
    "def all_subsets(n_elts):\n",
    "    '''\n",
    "        returns a list of 2^{n_elts} lists\n",
    "        each a different subset of {1, 2,...,n_elts}\n",
    "    '''\n",
    "    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\n",
    "    res = {i : res[i] for i in range(n_elts)}\n",
    "    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\n",
    "    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\n",
    "\n",
    "def get_residual(old_cube, new_cube, vertex):   #計算殘差\n",
    "    '''\n",
    "    returns: residual dictionary\n",
    "        \n",
    "        { edge : ▼_player_v[edge] - ▼v_player[edge] for edge in old_cube }\n",
    "    '''\n",
    "    assert set(old_cube.E_value.keys()) == set(new_cube.E_value.keys())     #判斷兩個字典中鍵值的組合是否相同。assert:\n",
    "    res = {}\n",
    "    for e in old_cube.E_value.keys():\n",
    "        res[e] = old_cube.partial_gradient[vertex][e] - new_cube.E_value[e] #對應某特徵的邊相減 即gradient_i_v - gradient_v_i(殘差)\n",
    "    return res\n",
    "count = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "#記得添加number of vertex\n",
    "def residual_norm(old_cube, vertex_values, vertex,num_features):     #old_cube是原本的SHAP得到的立方體\n",
    "    '''\n",
    "    old_cube: v, our game\n",
    "    vertex: player\n",
    "    vertex_values: v_player, proposed game\n",
    "    \n",
    "    assumes that the order of the values in vertex_values align with the order of the values in old_cube.V\n",
    "    \n",
    "    returns: || ▼_player_v - ▼v_player ||\n",
    "    '''\n",
    "    if count[vertex]==0 :\n",
    "        count[vertex] += 1\n",
    "    new_cube = Hypercube(num_features)\n",
    "    new_cube.set_vertex_values({str(_vertex) : vertex_values[j] for j, _vertex in enumerate(old_cube.V)})   #將數值設定成0.5\n",
    "    return np.sum([(r)**2 for r in get_residual(old_cube, new_cube, vertex).values()]), get_residual(old_cube, new_cube, vertex).values() #計算所有residual造成的影響加總\n",
    "#改一下參數\n",
    "def compute_residuals_v(old_cube,vertex_of_v_i_cube,_v,num_features):            #(instance cube,算出來的v_i cube,這個cube的指定feature)\n",
    "    new_vertex =  np.append(np.array(0), vertex_of_v_i_cube)\n",
    "    new_c = Hypercube(num_features)\n",
    "    coalitions = [np.array([])] + all_subsets(num_features)\n",
    "    b = {}\n",
    "    for i, coalition in enumerate(coalitions):\n",
    "        b[str(coalition)] = new_vertex[i]\n",
    "    new_c.set_vertex_values(b)\n",
    "    res = get_residual(old_cube,new_c,_v)\n",
    "    return(res.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:06.056292Z",
     "iopub.status.busy": "2024-05-10T05:48:06.056150Z",
     "iopub.status.idle": "2024-05-10T05:48:06.059077Z",
     "shell.execute_reply": "2024-05-10T05:48:06.058885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from itertools import combinations\\n\\ndef generate_all_subsets(num):\\n    num_set = [i for i in range(num)]\\n    return [np.array(s) for r in range(num+1) for s in combinations(num_set, r) ]\\ndef all_subsets(n_elts):\\n        #returns a list of 2^{n_elts} lists\\n        #each a different subset of {1, 2,...,n_elts}\\n    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\\n    res = {i : res[i] for i in range(n_elts)}\\n    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\\n    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\\na  = generate_all_subsets(5)\\n\\nb = [np.array([])]+all_subsets(5)\\nprint(a)\\nprint(b)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from itertools import combinations\n",
    "\n",
    "def generate_all_subsets(num):\n",
    "    num_set = [i for i in range(num)]\n",
    "    return [np.array(s) for r in range(num+1) for s in combinations(num_set, r) ]\n",
    "def all_subsets(n_elts):\n",
    "        #returns a list of 2^{n_elts} lists\n",
    "        #each a different subset of {1, 2,...,n_elts}\n",
    "    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\n",
    "    res = {i : res[i] for i in range(n_elts)}\n",
    "    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\n",
    "    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\n",
    "a  = generate_all_subsets(5)\n",
    "\n",
    "b = [np.array([])]+all_subsets(5)\n",
    "print(a)\n",
    "print(b)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "友達資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:06.086883Z",
     "iopub.status.busy": "2024-05-10T05:48:06.086742Z",
     "iopub.status.idle": "2024-05-10T05:48:36.576624Z",
     "shell.execute_reply": "2024-05-10T05:48:36.576248Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hcds_vol/private/luffy/anaconda3/envs/shap_res/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from data_process import read_selected_data, get_y,  split_data, compute_class_weights\n",
    "from dataset import BertDataset\n",
    "from model import BertClassifier\n",
    "from training import train_model\n",
    "from utils import draw_pics, initial_record\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "total_params = 14\n",
    "csv_file_path = '/hcds_vol/private/luffy/GANGAN-master/data/processed_data/v014_stage_1.csv'\n",
    "json_file_path = '/hcds_vol/private/luffy/GANGAN-master/data/controllable_para_v014_14.json'\n",
    "tool_name = 'ASCVD'\n",
    "epochs = 50000\n",
    "lr = 1e-5\n",
    "batch_size = 1024\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "save_folder_name = 'stage-1-param_'+str(total_params)+'-batch_'+str(batch_size)+'-lr_'+str(lr)\n",
    "with open(json_file_path, 'r') as f:\n",
    "    params = json.load(f)\n",
    "    f.close()\n",
    "s1_df = pd.read_csv(csv_file_path)\n",
    "#s1_df.shape\n",
    "all_key = list(params[tool_name]) \n",
    "params_list = []                #取得json檔內的特徵\n",
    "for key in all_key:\n",
    "    all_param = params[tool_name][key]\n",
    "    if(type(all_param) == list):\n",
    "        for param in all_param:\n",
    "             params_list.append(param)\n",
    "    else:\n",
    "        params_list.append(all_param)\n",
    "    \n",
    "# 取得Json檔內包含的特徵\n",
    "s1_df = s1_df[params_list] \n",
    "#print(params)\n",
    "s1_df.head(10)\n",
    "feature_df = s1_df.drop(['DFT_CNT'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:36.578744Z",
     "iopub.status.busy": "2024-05-10T05:48:36.578576Z",
     "iopub.status.idle": "2024-05-10T05:48:36.587900Z",
     "shell.execute_reply": "2024-05-10T05:48:36.587588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 8, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(feature_df)\n",
    "nf_df = pd.DataFrame(X_standardized)\n",
    "nf_df\n",
    "param_group = [] # [2,2,4,2]\n",
    "all_key = list(params[tool_name]) # ['EQ', 'PUMP', 'CH', 'VENT', 'y']\n",
    "all_key.remove('y')\n",
    "\n",
    "for key in all_key:\n",
    "    all_value = params[tool_name][key]\n",
    "    param_group.append(len(all_value))\n",
    "param_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:36.589196Z",
     "iopub.status.busy": "2024-05-10T05:48:36.589083Z",
     "iopub.status.idle": "2024-05-10T05:48:36.591627Z",
     "shell.execute_reply": "2024-05-10T05:48:36.591442Z"
    }
   },
   "outputs": [],
   "source": [
    "def padding_zero(df, tool_name, total_params, flag, params=params): \n",
    "    # 將一維參數matrix擴展為4維\n",
    "    data_arr = df.to_numpy()\n",
    "    result = []\n",
    "    for i in range(len(data_arr)):\n",
    "        arr_index = 0\n",
    "        empty_arr = np.zeros((4,total_params)) # chamber數 * 總參數數量\n",
    "        param_group_cp = param_group.copy()\n",
    "        for j in range(len(empty_arr)):\n",
    "            while(param_group_cp[j] > 0):\n",
    "                empty_arr[j][arr_index] = data_arr[i][arr_index]\n",
    "                param_group_cp[j] -= 1\n",
    "                arr_index += 1\n",
    "        \n",
    "        if(flag == 1): # bert.py使用\n",
    "            result.append(empty_arr)\n",
    "        if(flag == 2): # bert_du.py使用\n",
    "            result.append(empty_arr.tolist())\n",
    "    \n",
    "    if(flag == 1): # bert.py使用\n",
    "        result = pd.DataFrame({'X': [result[i] for i in range(len(result))]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:36.592837Z",
     "iopub.status.busy": "2024-05-10T05:48:36.592731Z",
     "iopub.status.idle": "2024-05-10T05:48:36.732147Z",
     "shell.execute_reply": "2024-05-10T05:48:36.731843Z"
    }
   },
   "outputs": [],
   "source": [
    "nf_df_4d = padding_zero(nf_df,tool_name,total_params,flag=1)\n",
    "nf_df_4d_object = nf_df_4d.to_numpy()\n",
    "nf_df_4d_list = []\n",
    "for i in range(len(nf_df_4d_object)):\n",
    "    nf_df_4d_list.append(nf_df_4d_object[i][0])\n",
    "nf_df_4d_arr = np.array(nf_df_4d_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "友達資料模型預測及平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:36.733660Z",
     "iopub.status.busy": "2024-05-10T05:48:36.733536Z",
     "iopub.status.idle": "2024-05-10T05:48:45.427444Z",
     "shell.execute_reply": "2024-05-10T05:48:45.427107Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "s1_model_path = '/hcds_vol/private/luffy/GANGAN-master/model/predictor/stage_1_checkpoint.pth'\n",
    "s1_model =  torch.load(s1_model_path).to(device)\n",
    "s1_model.eval()\n",
    "nf_df_4d_tensor = torch.tensor(nf_df_4d_arr,dtype=torch.float)\n",
    "dataset = TensorDataset(nf_df_4d_tensor)\n",
    "batch_size = 256\n",
    "loader = DataLoader(dataset, batch_size=batch_size)\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for batch_data in loader:\n",
    "        # 将数据移到指定的设备上（如 CUDA 设备）\n",
    "        batch_data = batch_data[0].to(device)\n",
    "        \n",
    "        # 将数据传递给模型进行推理\n",
    "        batch_output = s1_model(batch_data)\n",
    "        probs = (torch.nn.functional.softmax(batch_output, dim=1))\n",
    "        # 将输出保存起来\n",
    "        outputs += probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得模型平均和對應output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:45.428944Z",
     "iopub.status.busy": "2024-05-10T05:48:45.428848Z",
     "iopub.status.idle": "2024-05-10T05:48:46.094963Z",
     "shell.execute_reply": "2024-05-10T05:48:46.094481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_-TACT_TIME_mean</th>\n",
       "      <th>X_-CONVEYOR_SPEED_mean</th>\n",
       "      <th>PUMP_high</th>\n",
       "      <th>PUMP_low</th>\n",
       "      <th>CLN1_over-etching-ratio</th>\n",
       "      <th>CLN1_EPT_time</th>\n",
       "      <th>clean_count</th>\n",
       "      <th>EPT_clean_count_ratio</th>\n",
       "      <th>NH3_TREAT_-RF_FREQ-max</th>\n",
       "      <th>NH3_TREAT_-RF_FREQ-range</th>\n",
       "      <th>NH3_TREAT_-RF_FREQ-mean</th>\n",
       "      <th>NP_3_-MFC_VOL_SIH4-range</th>\n",
       "      <th>VENT_high</th>\n",
       "      <th>VENT_low</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>3150</td>\n",
       "      <td>29848.68000</td>\n",
       "      <td>10349.70000</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>9987</td>\n",
       "      <td>3</td>\n",
       "      <td>3329.000</td>\n",
       "      <td>13947</td>\n",
       "      <td>444</td>\n",
       "      <td>13614.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>14870.22222</td>\n",
       "      <td>5360.350000</td>\n",
       "      <td>0.922084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>4200</td>\n",
       "      <td>37183.04000</td>\n",
       "      <td>12891.48000</td>\n",
       "      <td>0.003292</td>\n",
       "      <td>10023</td>\n",
       "      <td>2</td>\n",
       "      <td>5011.500</td>\n",
       "      <td>13963</td>\n",
       "      <td>442</td>\n",
       "      <td>13623.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>16217.42000</td>\n",
       "      <td>8937.611111</td>\n",
       "      <td>0.672468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>4200</td>\n",
       "      <td>40499.96000</td>\n",
       "      <td>12198.94000</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>10059</td>\n",
       "      <td>3</td>\n",
       "      <td>3353.000</td>\n",
       "      <td>13948</td>\n",
       "      <td>418</td>\n",
       "      <td>13649.4286</td>\n",
       "      <td>1</td>\n",
       "      <td>17061.03750</td>\n",
       "      <td>5707.557143</td>\n",
       "      <td>0.576102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>4200</td>\n",
       "      <td>35524.30000</td>\n",
       "      <td>12731.66000</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>9999</td>\n",
       "      <td>3</td>\n",
       "      <td>3333.000</td>\n",
       "      <td>13979</td>\n",
       "      <td>451</td>\n",
       "      <td>13610.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>18121.24667</td>\n",
       "      <td>6610.381818</td>\n",
       "      <td>0.739274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>4200</td>\n",
       "      <td>40188.72000</td>\n",
       "      <td>10520.93333</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>9996</td>\n",
       "      <td>7</td>\n",
       "      <td>1428.000</td>\n",
       "      <td>13967</td>\n",
       "      <td>433</td>\n",
       "      <td>13642.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>16771.88824</td>\n",
       "      <td>9810.666667</td>\n",
       "      <td>0.859217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40971</th>\n",
       "      <td>140</td>\n",
       "      <td>3150</td>\n",
       "      <td>53015.43333</td>\n",
       "      <td>10077.01667</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>12069</td>\n",
       "      <td>8</td>\n",
       "      <td>1508.625</td>\n",
       "      <td>13994</td>\n",
       "      <td>468</td>\n",
       "      <td>13643.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>17537.10000</td>\n",
       "      <td>6312.560000</td>\n",
       "      <td>0.847003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40972</th>\n",
       "      <td>140</td>\n",
       "      <td>3150</td>\n",
       "      <td>53015.43333</td>\n",
       "      <td>12465.30000</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>12021</td>\n",
       "      <td>2</td>\n",
       "      <td>6010.500</td>\n",
       "      <td>13967</td>\n",
       "      <td>441</td>\n",
       "      <td>13636.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>16070.72500</td>\n",
       "      <td>7336.800000</td>\n",
       "      <td>0.829222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40973</th>\n",
       "      <td>140</td>\n",
       "      <td>3150</td>\n",
       "      <td>58385.13333</td>\n",
       "      <td>13051.28571</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>11994</td>\n",
       "      <td>3</td>\n",
       "      <td>3998.000</td>\n",
       "      <td>13975</td>\n",
       "      <td>450</td>\n",
       "      <td>13639.0833</td>\n",
       "      <td>1</td>\n",
       "      <td>16219.02500</td>\n",
       "      <td>6658.808333</td>\n",
       "      <td>0.837974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40974</th>\n",
       "      <td>140</td>\n",
       "      <td>3150</td>\n",
       "      <td>73952.03333</td>\n",
       "      <td>12358.76000</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>12021</td>\n",
       "      <td>3</td>\n",
       "      <td>4007.000</td>\n",
       "      <td>13979</td>\n",
       "      <td>448</td>\n",
       "      <td>13612.4545</td>\n",
       "      <td>1</td>\n",
       "      <td>18019.51429</td>\n",
       "      <td>7409.445455</td>\n",
       "      <td>0.826851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40975</th>\n",
       "      <td>140</td>\n",
       "      <td>3150</td>\n",
       "      <td>62161.70000</td>\n",
       "      <td>13165.42857</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>11994</td>\n",
       "      <td>4</td>\n",
       "      <td>2998.500</td>\n",
       "      <td>13968</td>\n",
       "      <td>446</td>\n",
       "      <td>13651.1429</td>\n",
       "      <td>1</td>\n",
       "      <td>16464.53125</td>\n",
       "      <td>7022.027273</td>\n",
       "      <td>0.870864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40976 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X_-TACT_TIME_mean  X_-CONVEYOR_SPEED_mean    PUMP_high     PUMP_low  \\\n",
       "0                     90                    3150  29848.68000  10349.70000   \n",
       "1                     90                    4200  37183.04000  12891.48000   \n",
       "2                     90                    4200  40499.96000  12198.94000   \n",
       "3                     90                    4200  35524.30000  12731.66000   \n",
       "4                     90                    4200  40188.72000  10520.93333   \n",
       "...                  ...                     ...          ...          ...   \n",
       "40971                140                    3150  53015.43333  10077.01667   \n",
       "40972                140                    3150  53015.43333  12465.30000   \n",
       "40973                140                    3150  58385.13333  13051.28571   \n",
       "40974                140                    3150  73952.03333  12358.76000   \n",
       "40975                140                    3150  62161.70000  13165.42857   \n",
       "\n",
       "       CLN1_over-etching-ratio  CLN1_EPT_time  clean_count  \\\n",
       "0                     0.001802           9987            3   \n",
       "1                     0.003292          10023            2   \n",
       "2                     0.005368          10059            3   \n",
       "3                     0.008401           9999            3   \n",
       "4                     0.017107           9996            7   \n",
       "...                        ...            ...          ...   \n",
       "40971                 0.001491          12069            8   \n",
       "40972                 0.006489          12021            2   \n",
       "40973                 0.001251          11994            3   \n",
       "40974                 0.006489          12021            3   \n",
       "40975                 0.001251          11994            4   \n",
       "\n",
       "       EPT_clean_count_ratio  NH3_TREAT_-RF_FREQ-max  \\\n",
       "0                   3329.000                   13947   \n",
       "1                   5011.500                   13963   \n",
       "2                   3353.000                   13948   \n",
       "3                   3333.000                   13979   \n",
       "4                   1428.000                   13967   \n",
       "...                      ...                     ...   \n",
       "40971               1508.625                   13994   \n",
       "40972               6010.500                   13967   \n",
       "40973               3998.000                   13975   \n",
       "40974               4007.000                   13979   \n",
       "40975               2998.500                   13968   \n",
       "\n",
       "       NH3_TREAT_-RF_FREQ-range  NH3_TREAT_-RF_FREQ-mean  \\\n",
       "0                           444               13614.0000   \n",
       "1                           442               13623.0000   \n",
       "2                           418               13649.4286   \n",
       "3                           451               13610.0000   \n",
       "4                           433               13642.2500   \n",
       "...                         ...                      ...   \n",
       "40971                       468               13643.0000   \n",
       "40972                       441               13636.2500   \n",
       "40973                       450               13639.0833   \n",
       "40974                       448               13612.4545   \n",
       "40975                       446               13651.1429   \n",
       "\n",
       "       NP_3_-MFC_VOL_SIH4-range    VENT_high     VENT_low    Output  \n",
       "0                             0  14870.22222  5360.350000  0.922084  \n",
       "1                             1  16217.42000  8937.611111  0.672468  \n",
       "2                             1  17061.03750  5707.557143  0.576102  \n",
       "3                             1  18121.24667  6610.381818  0.739274  \n",
       "4                             1  16771.88824  9810.666667  0.859217  \n",
       "...                         ...          ...          ...       ...  \n",
       "40971                         1  17537.10000  6312.560000  0.847003  \n",
       "40972                         1  16070.72500  7336.800000  0.829222  \n",
       "40973                         1  16219.02500  6658.808333  0.837974  \n",
       "40974                         1  18019.51429  7409.445455  0.826851  \n",
       "40975                         1  16464.53125  7022.027273  0.870864  \n",
       "\n",
       "[40976 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_arr = np.array([output.cpu().numpy()[0] for output in outputs])\n",
    "output_df = pd.DataFrame({'Output': output_arr})\n",
    "new_df = pd.concat([feature_df,output_df],axis=1)\n",
    "new_df.to_csv('data_with_output.csv',index=False)\n",
    "new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:46.097834Z",
     "iopub.status.busy": "2024-05-10T05:48:46.097582Z",
     "iopub.status.idle": "2024-05-10T05:48:46.102930Z",
     "shell.execute_reply": "2024-05-10T05:48:46.102597Z"
    }
   },
   "outputs": [],
   "source": [
    "def send_to_model(data):\n",
    "    if 'Output' in data.columns:\n",
    "        data = data.drop(columns=['Output'])\n",
    "    data_standardized = scaler.transform(data)\n",
    "    data_standardized_df = pd.DataFrame(data_standardized)\n",
    "    data_4d = padding_zero(data_standardized_df,tool_name,total_params,flag=1)\n",
    "    data_4d_object =  data_4d.to_numpy()\n",
    "    data_4d_list = []\n",
    "    for i in range(len(data_4d_object)):\n",
    "        data_4d_list.append(data_4d_object[i][0])\n",
    "    data_4d_arr = np.array(data_4d_list)\n",
    "    data_4d_tensor = torch.tensor(data_4d_arr,dtype=torch.float)\n",
    "    my_dataset = TensorDataset(data_4d_tensor)\n",
    "    batch_size = 256\n",
    "    my_loader = DataLoader(my_dataset, batch_size=batch_size,num_workers=4)\n",
    "    data_output = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in my_loader:\n",
    "        # 将数据移到指定的设备上（如 CUDA 设备）\n",
    "            batch_data = batch_data[0].to(device)\n",
    "        \n",
    "        # 将数据传递给模型进行推理\n",
    "            batch_output = s1_model(batch_data)\n",
    "            probs = (torch.nn.functional.softmax(batch_output, dim=1))\n",
    "        # 将输出保存起来\n",
    "            data_output += probs\n",
    "    data_output_arr = np.array([output.cpu().numpy()[0] for output in data_output])\n",
    "    data_expectation_out = data_output_arr.mean()\n",
    "    return data_expectation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T05:48:46.105029Z",
     "iopub.status.busy": "2024-05-10T05:48:46.104817Z",
     "iopub.status.idle": "2024-05-10T07:08:45.217304Z",
     "shell.execute_reply": "2024-05-10T07:08:45.216899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31661\n",
      "0.7392740845680237\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import warnings\n",
    "import itertools\n",
    "# 過濾掉FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "def all_subsets(n_elts):\n",
    "    '''\n",
    "        returns a list of 2^{n_elts} lists\n",
    "        each a different subset of {1, 2,...,n_elts}\n",
    "    '''\n",
    "    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\n",
    "    res = {i : res[i] for i in range(n_elts)}\n",
    "    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\n",
    "    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\n",
    "para_num = 14\n",
    "AUO_coalitions = [np.array([])] + all_subsets(para_num) \n",
    "coalition_estimated_values = {}\n",
    "instance = new_df.iloc[3]\n",
    "#mean_exp = new_df['Output'].mean()\n",
    "flag=0\n",
    "count_n = 1\n",
    "selected_data = new_df.copy()\n",
    "selected_data = selected_data[(selected_data['PUMP_low']<20000) & \n",
    "                              (selected_data['PUMP_high']>20000) & \n",
    "                              (selected_data['VENT_low']<10000) & \n",
    "                              (selected_data['VENT_high']>10000) &\n",
    "                              (selected_data['NH3_TREAT_-RF_FREQ-max']>13800)&\n",
    "                              (selected_data['NH3_TREAT_-RF_FREQ-mean']<13800)\n",
    "                                                            ]\n",
    "print(len(selected_data))\n",
    "sample_df = selected_data.sample(n=1000,random_state=42)\n",
    "instance.to_csv('instance_3d.csv',index=True)\n",
    "sample_df.to_csv('background_dataset_2.csv',index=True)\n",
    "mean_exp = sample_df['Output'].mean()\n",
    "print(instance['Output'])\n",
    "for coalition in AUO_coalitions:\n",
    "    synth = sample_df.copy()                   #用copy()才不會去更改到原始的dataframe\n",
    "    if len(coalition)!=0:\n",
    "        #print(synth.iloc[:,coalition],instance[coalition])\n",
    "        synth.iloc[:,coalition] = instance.iloc[coalition]\n",
    "        \n",
    "        '''if len(coalition)==3 and flag==0:\n",
    "            print(instance)\n",
    "            print(synth.head(5))\n",
    "            flag=1'''\n",
    "        #if (2 in coalition and 3 not in coalition):\n",
    "        #    PUMP_high = instance.iloc[2]\n",
    "        #    synth = synth[synth.iloc[:,3]<PUMP_high]\n",
    "            #print('good')\n",
    "            \n",
    "    #if count_n==100:\n",
    "        #print('資料集長度:',len(synth))\n",
    "        #print('feature數:',len(coalition))\n",
    "        #print('資料: ',synth)\n",
    "        #print(coalition)\n",
    "        #count_n = 0\n",
    "\n",
    "    count_n += 1\n",
    "    Exp = send_to_model(synth)\n",
    "    impact = Exp - mean_exp\n",
    "\n",
    "    coalition_estimated_values[str(coalition)] = impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T07:08:45.219246Z",
     "iopub.status.busy": "2024-05-10T07:08:45.219139Z",
     "iopub.status.idle": "2024-05-10T07:08:57.947038Z",
     "shell.execute_reply": "2024-05-10T07:08:57.946689Z"
    }
   },
   "outputs": [],
   "source": [
    "AUOcube = Hypercube(para_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T07:08:57.948908Z",
     "iopub.status.busy": "2024-05-10T07:08:57.948800Z",
     "iopub.status.idle": "2024-05-10T07:08:57.952323Z",
     "shell.execute_reply": "2024-05-10T07:08:57.952126Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "AUOcube.set_vertex_values(coalition_estimated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T07:08:57.954182Z",
     "iopub.status.busy": "2024-05-10T07:08:57.953914Z",
     "iopub.status.idle": "2024-05-10T07:08:57.956615Z",
     "shell.execute_reply": "2024-05-10T07:08:57.956359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_-TACT_TIME_mean              90.000000\n",
      "X_-CONVEYOR_SPEED_mean       4200.000000\n",
      "PUMP_high                   35524.300000\n",
      "PUMP_low                    12731.660000\n",
      "CLN1_over-etching-ratio         0.008401\n",
      "CLN1_EPT_time                9999.000000\n",
      "clean_count                     3.000000\n",
      "EPT_clean_count_ratio        3333.000000\n",
      "NH3_TREAT_-RF_FREQ-max      13979.000000\n",
      "NH3_TREAT_-RF_FREQ-range      451.000000\n",
      "NH3_TREAT_-RF_FREQ-mean     13610.000000\n",
      "NP_3_-MFC_VOL_SIH4-range        1.000000\n",
      "VENT_high                   18121.246670\n",
      "VENT_low                     6610.381818\n",
      "Output                          0.739274\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T07:08:57.957677Z",
     "iopub.status.busy": "2024-05-10T07:08:57.957569Z",
     "iopub.status.idle": "2024-05-10T16:22:51.070158Z",
     "shell.execute_reply": "2024-05-10T16:22:51.068330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9111927518118952\n",
      "shapley_value:  0.0906682993606435 residual sum:  17.859217019275853\n",
      "norm:  0.38752968065376203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9137679153631387\n",
      "shapley_value:  -0.0030395748870912613 residual sum:  13.668549690279308\n",
      "norm:  0.7303436836494895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9717026734080273\n",
      "shapley_value:  0.01300555405364303 residual sum:  9.166097890179273\n",
      "norm:  0.7100974649534555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9842638882892442\n",
      "shapley_value:  -0.016702505769013595 residual sum:  1.2860491920262003\n",
      "norm:  0.6000056719963048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9661895509621751\n",
      "shapley_value:  -0.01039884203079711 residual sum:  3.258505443337721\n",
      "norm:  0.7308129420930272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9933176904762796\n",
      "shapley_value:  -0.034518456366253475 residual sum:  6.639273526094362\n",
      "norm:  0.5666728360461107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9331925408062065\n",
      "shapley_value:  0.016769082874361026 residual sum:  2.3454405323037113\n",
      "norm:  0.665451106223727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9825002793698759\n",
      "shapley_value:  0.006496756918912914 residual sum:  0.15847605627031333\n",
      "norm:  0.6223514440352849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.99407112193655\n",
      "shapley_value:  0.005370224636837337 residual sum:  0.048240583023366645\n",
      "norm:  0.42746667973434865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9947889306367211\n",
      "shapley_value:  0.0035875721968676817 residual sum:  0.020771980086089492\n",
      "norm:  0.3936535884784277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.863566712442392\n",
      "shapley_value:  0.005186238801232455 residual sum:  0.6518213589549336\n",
      "norm:  0.6891970785534222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9957816221917998\n",
      "shapley_value:  -7.695851642635646e-05 residual sum:  1.9606242847663784e-05\n",
      "norm:  0.5064994823074427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9883913678539039\n",
      "shapley_value:  -0.023294109870391475 residual sum:  1.710123369910234\n",
      "norm:  0.5680606879556699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9940878246919131\n",
      "shapley_value:  0.010515549087552492 residual sum:  0.4846419085834371\n",
      "norm:  0.5359576836935946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p_n = []\n",
    "for i  in range(para_num):\n",
    "    AUOcube.trans_to_matrix(feature_i=i)\n",
    "    res = AUOcube.shapley_residuals_in_matrix()\n",
    "    #print(new_df.columns[i],'residuals_of_feature',i)\n",
    "    save_json(res[0],feature_name=params_list[i])\n",
    "    save_res_json(res[1],feature_name=params_list[i])\n",
    "    p_n.append(res[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T16:22:51.160625Z",
     "iopub.status.busy": "2024-05-10T16:22:51.160004Z",
     "iopub.status.idle": "2024-05-10T16:22:51.196475Z",
     "shell.execute_reply": "2024-05-10T16:22:51.194867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118.91933550356596, 25.62523640515409, 18.178103280602798, 3.5722913263428637, 6.101069767894579, 20.675488120230625, 5.296538376569728, 0.409159135144364, 0.2640024833699073, 0.13404464475232203, 1.3722768333581072, 7.64251616516276e-05, 5.299537518078623, 1.6871743462766489]\n"
     ]
    }
   ],
   "source": [
    "print(p_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shap_res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
