{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:03:20.079124Z",
     "iopub.status.busy": "2024-05-01T17:03:20.078907Z",
     "iopub.status.idle": "2024-05-01T17:03:21.069905Z",
     "shell.execute_reply": "2024-05-01T17:03:21.068974Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import bisect\n",
    "import math\n",
    "import json\n",
    "class Hypercube:                #超立方體\n",
    "    '''\n",
    "    A class to create a hypercube object which stores values on vertices\n",
    "    and values on the edges between neighboring vertices\n",
    "    '''    \n",
    "    #輸入維度、(點鍵值)、(點值)\n",
    "    def __init__(self, n_vertices, vertex_keys = None, vertex_values = None):   \n",
    "        self.n_vertices = n_vertices\n",
    "        self.v_num = 2**self.n_vertices\n",
    "        self.V = [np.array([])] + all_subsets(n_vertices)   #所有子集包含空集，即所有點\n",
    "        self.V_value = {str(v) : 0. for v in self.V}         #所有點值  先設為0\n",
    "        self.E = []\n",
    "        self.E_value = {}\n",
    "        self.partial_gradient = {vertex : {} for vertex in range(n_vertices)}   #各個維度的partial gradient\n",
    "        self.matrix = np.full((self.v_num,self.v_num),np.nan)                   #原始立方體對應到的矩陣\n",
    "        self.partial_gradient_matrix = np.full((self.v_num,self.v_num),np.nan)  #對特定 feature的partial gradient\n",
    "        self.vi_matrix = np.full((self.v_num,self.v_num),np.nan)                #v_i對應到的矩陣\n",
    "        self.res_matrix = np.full((self.v_num,self.v_num),np.nan)               #residual的matrix\n",
    "        self.sv = 0\n",
    " \n",
    "    def set_vertex_values(self, vertex_values):         #設置點值\n",
    "        for v in vertex_values:                         #用鍵值來做查找\n",
    "            self.V_value[v] = vertex_values[v]\n",
    "            \n",
    "        # edge values are the differences between neighboring vertex values\n",
    "        #self._calculate_edges()\n",
    "        \n",
    "    def _calculate_edges(self):                 #計算邊值\n",
    "        \n",
    "        # calculate the usual gradients: the difference between neighboring edges\n",
    "        for i, v in enumerate(self.V):\n",
    "            for _v in self.V[i+1:]:\n",
    "                if self._vertices_form_a_valid_edge(v, _v):\n",
    "                    self.E.append((v, _v))\n",
    "                    self.E_value[str((v, _v))] = self.V_value[str(_v)] - self.V_value[str(v)]\n",
    "        \n",
    "        # calculate partial gradients\n",
    "        for vertex in range(self.n_vertices):\n",
    "            self.partial_gradient[vertex] = self.E_value.copy()\n",
    "            for v, _v in self.E:\n",
    "                is_relevant_edge_for_partial_gradient = (vertex in v and vertex not in _v) or (vertex in _v and vertex not in v)\n",
    "                if not is_relevant_edge_for_partial_gradient:\n",
    "                    self.partial_gradient[vertex][str((v, _v))] = 0.\n",
    "            \n",
    "    def _vertices_form_a_valid_edge(self, v, _v):       #檢查交集和是否相鄰\n",
    "        # vertices are neighbors in a hypercube\n",
    "        # if they differ by exactly one element\n",
    "        differ_in_size_by_1 = (abs(len(v) - len(_v)) == 1)      #差距是1\n",
    "    \n",
    "        the_intersection = np.intersect1d(v, _v)                #兩個集合的交集\n",
    "        #print(type(v[0]),type(_v[0]),type(the_intersection[0]))\n",
    "        intersection_is_nonempty = len(the_intersection) > 0 or len(v)==0 or len(_v) == 0   #交集大於0或v,_v是空集\n",
    "        is_intersection = False                         \n",
    "        if len(the_intersection)>0:                              \n",
    "            if len(the_intersection)==len(v) or len(the_intersection)==len(_v):\n",
    "                is_intersection = True\n",
    "        else:\n",
    "            if len(v)==0 and len(_v)==1:\n",
    "                is_intersection = True\n",
    "       # print(is_intersection)\n",
    "        return differ_in_size_by_1 and intersection_is_nonempty and is_intersection\n",
    "    \n",
    "    #create matrix for Hypercube\n",
    "    def trans_to_matrix(self,feature_i):                #超立方體轉換成矩陣\n",
    "        for i, v in enumerate(self.V):                  #對立方體上所有點\n",
    "            for j,_v in enumerate(self.V[i+1:]):        \n",
    "                if self._vertices_form_a_valid_edge(v, _v):     #是否相交\n",
    "                    self.matrix[i][i+j+1] = self.V_value[str(_v)] - self.V_value[str(v)]    #獲得matrix\n",
    "                    self.matrix[i+j+1][i] = self.V_value[str(v)] - self.V_value[str(_v)]\n",
    "        \n",
    "            \n",
    "        self.partial_gradient_matrix = self.matrix.copy()       #把原始立方體複製下來，保留i方向\n",
    "        self.my_list = []\n",
    "        self.partial_gradient_vector = np.array([])\n",
    "        self.weight_vector = np.array([])\n",
    "        for j, v in enumerate(self.V):\n",
    "            for k,_v in enumerate(self.V[j+1:]):\n",
    "                if self._vertices_form_a_valid_edge(v, _v):     #如果是邊\n",
    "                    is_relevant_edge_for_partial_gradient = (feature_i in v and feature_i not in _v) or (feature_i in _v and feature_i not in v)\n",
    "                    if not is_relevant_edge_for_partial_gradient:           #如果 特徵i不在v 或_v，把那條邊設成0\n",
    "                        self.partial_gradient_matrix[j][j+k+1] = 0.\n",
    "                        self.partial_gradient_matrix[j+k+1][j] = 0.\n",
    "                    else:\n",
    "                        self.partial_gradient_vector = np.append(self.partial_gradient_vector,self.partial_gradient_matrix[j][j+k+1])      #比較向量1\n",
    "                        subset_len = len(v)\n",
    "                        weight = 1./(math.comb(self.n_vertices,subset_len)*(self.n_vertices-subset_len))            #Shapley value權重參數\n",
    "                        self.weight_vector = np.append(self.weight_vector,weight)\n",
    "                        self.my_list.append((j,j+k+1))          \n",
    "        #self.vi[feature_i] = self.shapley_residuals_in_matrix()\n",
    "        #self.vi[i] = self.shapley_residuals_in_matrix\n",
    "    \n",
    "    #minimize the function (gradient_x - partial_gradient_i)^2 最小化l2_norm\n",
    "    def shapley_residuals_in_matrix(self):\n",
    "            derivative_i  = np.full((self.v_num,self.v_num),0.)      #計算微分後得到的方程式矩陣 A\n",
    "            b_i = np.array([0.]*self.v_num)                          #得到Ax = b 的 b向量值\n",
    "            for j  in range(self.v_num):                            #對矩陣的每個點\n",
    "                for k in range(self.v_num):\n",
    "                    if np.isnan(self.partial_gradient_matrix[j][k]):    #不用計算nan\n",
    "                        continue\n",
    "                    #elif j == 0 or k ==0:                               #如果是跟原點相鄰\n",
    "                     #   derivative_i[j][j] += 1.                       #係數+1\n",
    "                      #  b_i[j] += - self.partial_gradient_matrix[j][k]     #x_j-x_i-partial_gradient\n",
    "                    else:                                               \n",
    "                        derivative_i[j][j] += 1.                         \n",
    "                        derivative_i[j][k] += -1.\n",
    "                        b_i[j] += - self.partial_gradient_matrix[j][k]\n",
    "            A = derivative_i[1:,1:]                                    #只要x_i for i!=0\n",
    "            B = b_i[1:]                                                #保留b_i\n",
    "            res = 0.\n",
    "            A_inverse = np.linalg.inv(A)                               #算inverse matrix\n",
    "            vi = np.insert(np.dot(A_inverse,B),0,0.)                    #vi  = b/A #開頭補0\n",
    "            vi_V =  [np.array([])] + all_subsets(self.n_vertices)\n",
    "            vi_V_value = {str(v) : 0. for v in vi_V} \n",
    "            for k,v in enumerate(vi_V):               \n",
    "                vi_V_value[str(v)] = vi[k]\n",
    "            self.vi_vector = np.array([])                              #比較向量#2\n",
    "            for i, v in enumerate(vi_V):\n",
    "                for j,_v in enumerate(vi_V[i+1:]):\n",
    "                    if self._vertices_form_a_valid_edge(v, _v):\n",
    "                        self.vi_matrix[i][i+j+1] = vi_V_value[str(_v)] - vi_V_value[str(v)]\n",
    "                        self.vi_matrix[i+j+1][i] = vi_V_value[str(v)] - vi_V_value[str(_v)]\n",
    "                        self.res_matrix[i][i+j+1] = self.partial_gradient_matrix[i][i+j+1] - self.vi_matrix[i][i+j+1]\n",
    "                        self.res_matrix[i+j+1][i] = self.partial_gradient_matrix[i+j+1][i] - self.vi_matrix[i+j+1][i]\n",
    "                        res += abs(self.res_matrix[i][i+j+1])\n",
    "                        if (i,i+j+1) in self.my_list:\n",
    "                            self.vi_vector = np.append(self.vi_vector,self.vi_matrix[i][i+j+1])     #比較向量#2\n",
    "            #print(self.my_list)\n",
    "            #print(self.partial_gradient_vector,self.vi_vector)\n",
    "            vector_A = self.weight_vector*self.partial_gradient_vector\n",
    "            vector_B = self.weight_vector*self.vi_vector\n",
    "            cos_sim = self.cos_sim(vector_A,vector_B)\n",
    "            print('cos_sim = ',cos_sim)\n",
    "            self.sv += vi[-1]\n",
    "            print('shapley_value: ',vi[-1],'residual sum: ',res)\n",
    "            print(self.sv)\n",
    "            #print('residuals_sum:',res,'shapley_value: ',vi)\n",
    "            res =  res/vi[-1]\n",
    "            \n",
    "            return vi_V_value\n",
    "    \n",
    "    def cos_sim(self,a,b):\n",
    "        dot_product = np.dot(a, b)\n",
    "        norm_a = np.linalg.norm(a)\n",
    "        norm_b = np.linalg.norm(b)\n",
    "        similarity = dot_product / (norm_a * norm_b)\n",
    "        return similarity\n",
    "            \n",
    "####################     \n",
    "def save_json(dic,feature_name):\n",
    "    filename = f\"dic_{feature_name}.json\"\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(dic, json_file)\n",
    "            \n",
    "        \n",
    "def all_subsets(n_elts):\n",
    "    '''\n",
    "        returns a list of 2^{n_elts} lists\n",
    "        each a different subset of {1, 2,...,n_elts}\n",
    "    '''\n",
    "    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\n",
    "    res = {i : res[i] for i in range(n_elts)}\n",
    "    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\n",
    "    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\n",
    "\n",
    "def get_residual(old_cube, new_cube, vertex):   #計算殘差\n",
    "    '''\n",
    "    returns: residual dictionary\n",
    "        \n",
    "        { edge : ▼_player_v[edge] - ▼v_player[edge] for edge in old_cube }\n",
    "    '''\n",
    "    assert set(old_cube.E_value.keys()) == set(new_cube.E_value.keys())     #判斷兩個字典中鍵值的組合是否相同。assert:\n",
    "    res = {}\n",
    "    for e in old_cube.E_value.keys():\n",
    "        res[e] = old_cube.partial_gradient[vertex][e] - new_cube.E_value[e] #對應某特徵的邊相減 即gradient_i_v - gradient_v_i(殘差)\n",
    "    return res\n",
    "count = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "#記得添加number of vertex\n",
    "def residual_norm(old_cube, vertex_values, vertex,num_features):     #old_cube是原本的SHAP得到的立方體\n",
    "    '''\n",
    "    old_cube: v, our game\n",
    "    vertex: player\n",
    "    vertex_values: v_player, proposed game\n",
    "    \n",
    "    assumes that the order of the values in vertex_values align with the order of the values in old_cube.V\n",
    "    \n",
    "    returns: || ▼_player_v - ▼v_player ||\n",
    "    '''\n",
    "    if count[vertex]==0 :\n",
    "        count[vertex] += 1\n",
    "    new_cube = Hypercube(num_features)\n",
    "    new_cube.set_vertex_values({str(_vertex) : vertex_values[j] for j, _vertex in enumerate(old_cube.V)})   #將數值設定成0.5\n",
    "    return np.sum([(r)**2 for r in get_residual(old_cube, new_cube, vertex).values()]), get_residual(old_cube, new_cube, vertex).values() #計算所有residual造成的影響加總\n",
    "#改一下參數\n",
    "def compute_residuals_v(old_cube,vertex_of_v_i_cube,_v,num_features):            #(instance cube,算出來的v_i cube,這個cube的指定feature)\n",
    "    new_vertex =  np.append(np.array(0), vertex_of_v_i_cube)\n",
    "    new_c = Hypercube(num_features)\n",
    "    coalitions = [np.array([])] + all_subsets(num_features)\n",
    "    b = {}\n",
    "    for i, coalition in enumerate(coalitions):\n",
    "        b[str(coalition)] = new_vertex[i]\n",
    "    new_c.set_vertex_values(b)\n",
    "    res = get_residual(old_cube,new_c,_v)\n",
    "    return(res.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:03:21.093522Z",
     "iopub.status.busy": "2024-05-01T17:03:21.089539Z",
     "iopub.status.idle": "2024-05-01T17:03:21.118633Z",
     "shell.execute_reply": "2024-05-01T17:03:21.116961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    for k  in range(3):\n",
    "        a.append((i,k))\n",
    "if (4,2) in a:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:03:21.152883Z",
     "iopub.status.busy": "2024-05-01T17:03:21.152284Z",
     "iopub.status.idle": "2024-05-01T17:03:21.160399Z",
     "shell.execute_reply": "2024-05-01T17:03:21.160018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from itertools import combinations\\n\\ndef generate_all_subsets(num):\\n    num_set = [i for i in range(num)]\\n    return [np.array(s) for r in range(num+1) for s in combinations(num_set, r) ]\\ndef all_subsets(n_elts):\\n        #returns a list of 2^{n_elts} lists\\n        #each a different subset of {1, 2,...,n_elts}\\n    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\\n    res = {i : res[i] for i in range(n_elts)}\\n    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\\n    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\\na  = generate_all_subsets(5)\\n\\nb = [np.array([])]+all_subsets(5)\\nprint(a)\\nprint(b)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from itertools import combinations\n",
    "\n",
    "def generate_all_subsets(num):\n",
    "    num_set = [i for i in range(num)]\n",
    "    return [np.array(s) for r in range(num+1) for s in combinations(num_set, r) ]\n",
    "def all_subsets(n_elts):\n",
    "        #returns a list of 2^{n_elts} lists\n",
    "        #each a different subset of {1, 2,...,n_elts}\n",
    "    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\n",
    "    res = {i : res[i] for i in range(n_elts)}\n",
    "    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\n",
    "    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\n",
    "a  = generate_all_subsets(5)\n",
    "\n",
    "b = [np.array([])]+all_subsets(5)\n",
    "print(a)\n",
    "print(b)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "友達資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:03:21.166128Z",
     "iopub.status.busy": "2024-05-01T17:03:21.165763Z",
     "iopub.status.idle": "2024-05-01T17:03:57.646129Z",
     "shell.execute_reply": "2024-05-01T17:03:57.644836Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hcds_vol/private/luffy/anaconda3/envs/shap_res/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from data_process import read_selected_data, get_y,  split_data, compute_class_weights\n",
    "from dataset import BertDataset\n",
    "from model import BertClassifier\n",
    "from training import train_model\n",
    "from utils import draw_pics, initial_record\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "total_params = 14\n",
    "csv_file_path = '/hcds_vol/private/luffy/GANGAN-master/data/processed_data/v014_stage_1.csv'\n",
    "json_file_path = '/hcds_vol/private/luffy/GANGAN-master/data/controllable_para_v014_14.json'\n",
    "tool_name = 'ASCVD'\n",
    "epochs = 50000\n",
    "lr = 1e-5\n",
    "batch_size = 1024\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "save_folder_name = 'stage-1-param_'+str(total_params)+'-batch_'+str(batch_size)+'-lr_'+str(lr)\n",
    "with open(json_file_path, 'r') as f:\n",
    "    params = json.load(f)\n",
    "    f.close()\n",
    "s1_df = pd.read_csv(csv_file_path)\n",
    "#s1_df.shape\n",
    "all_key = list(params[tool_name]) \n",
    "params_list = []                #取得json檔內的特徵\n",
    "for key in all_key:\n",
    "    all_param = params[tool_name][key]\n",
    "    if(type(all_param) == list):\n",
    "        for param in all_param:\n",
    "             params_list.append(param)\n",
    "    else:\n",
    "        params_list.append(all_param)\n",
    "    \n",
    "# 取得Json檔內包含的特徵\n",
    "s1_df = s1_df[params_list] \n",
    "#print(params)\n",
    "s1_df.head(10)\n",
    "feature_df = s1_df.drop(['DFT_CNT'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:03:57.667683Z",
     "iopub.status.busy": "2024-05-01T17:03:57.665841Z",
     "iopub.status.idle": "2024-05-01T17:03:57.701674Z",
     "shell.execute_reply": "2024-05-01T17:03:57.698780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 8, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(feature_df)\n",
    "nf_df = pd.DataFrame(X_standardized)\n",
    "nf_df\n",
    "param_group = [] # [2,2,4,2]\n",
    "all_key = list(params[tool_name]) # ['EQ', 'PUMP', 'CH', 'VENT', 'y']\n",
    "all_key.remove('y')\n",
    "\n",
    "for key in all_key:\n",
    "    all_value = params[tool_name][key]\n",
    "    param_group.append(len(all_value))\n",
    "param_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:03:57.715626Z",
     "iopub.status.busy": "2024-05-01T17:03:57.714934Z",
     "iopub.status.idle": "2024-05-01T17:03:57.724520Z",
     "shell.execute_reply": "2024-05-01T17:03:57.723726Z"
    }
   },
   "outputs": [],
   "source": [
    "def padding_zero(df, tool_name, total_params, flag, params=params): \n",
    "    # 將一維參數matrix擴展為4維\n",
    "    data_arr = df.to_numpy()\n",
    "    result = []\n",
    "    for i in range(len(data_arr)):\n",
    "        arr_index = 0\n",
    "        empty_arr = np.zeros((4,total_params)) # chamber數 * 總參數數量\n",
    "        param_group_cp = param_group.copy()\n",
    "        for j in range(len(empty_arr)):\n",
    "            while(param_group_cp[j] > 0):\n",
    "                empty_arr[j][arr_index] = data_arr[i][arr_index]\n",
    "                param_group_cp[j] -= 1\n",
    "                arr_index += 1\n",
    "        \n",
    "        if(flag == 1): # bert.py使用\n",
    "            result.append(empty_arr)\n",
    "        if(flag == 2): # bert_du.py使用\n",
    "            result.append(empty_arr.tolist())\n",
    "    \n",
    "    if(flag == 1): # bert.py使用\n",
    "        result = pd.DataFrame({'X': [result[i] for i in range(len(result))]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:03:57.727492Z",
     "iopub.status.busy": "2024-05-01T17:03:57.727079Z",
     "iopub.status.idle": "2024-05-01T17:03:58.069259Z",
     "shell.execute_reply": "2024-05-01T17:03:58.068443Z"
    }
   },
   "outputs": [],
   "source": [
    "nf_df_4d = padding_zero(nf_df,tool_name,total_params,flag=1)\n",
    "nf_df_4d_object = nf_df_4d.to_numpy()\n",
    "nf_df_4d_list = []\n",
    "for i in range(len(nf_df_4d_object)):\n",
    "    nf_df_4d_list.append(nf_df_4d_object[i][0])\n",
    "nf_df_4d_arr = np.array(nf_df_4d_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "友達資料模型預測及平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:03:58.073815Z",
     "iopub.status.busy": "2024-05-01T17:03:58.073223Z",
     "iopub.status.idle": "2024-05-01T17:04:06.837352Z",
     "shell.execute_reply": "2024-05-01T17:04:06.836381Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "s1_model_path = '/hcds_vol/private/luffy/GANGAN-master/model/predictor/stage_1_checkpoint.pth'\n",
    "s1_model =  torch.load(s1_model_path).to(device)\n",
    "s1_model.eval()\n",
    "nf_df_4d_tensor = torch.tensor(nf_df_4d_arr,dtype=torch.float)\n",
    "dataset = TensorDataset(nf_df_4d_tensor)\n",
    "batch_size = 256\n",
    "loader = DataLoader(dataset, batch_size=batch_size)\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for batch_data in loader:\n",
    "        # 将数据移到指定的设备上（如 CUDA 设备）\n",
    "        batch_data = batch_data[0].to(device)\n",
    "        \n",
    "        # 将数据传递给模型进行推理\n",
    "        batch_output = s1_model(batch_data)\n",
    "        probs = (torch.nn.functional.softmax(batch_output, dim=1))\n",
    "        # 将输出保存起来\n",
    "        outputs += probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得模型平均和對應output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:04:06.841487Z",
     "iopub.status.busy": "2024-05-01T17:04:06.840990Z",
     "iopub.status.idle": "2024-05-01T17:04:07.512228Z",
     "shell.execute_reply": "2024-05-01T17:04:07.510985Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "output_arr = np.array([output.cpu().numpy()[0] for output in outputs])\n",
    "output_df = pd.DataFrame({'Output': output_arr})\n",
    "new_df = pd.concat([feature_df,output_df],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:04:07.521906Z",
     "iopub.status.busy": "2024-05-01T17:04:07.521074Z",
     "iopub.status.idle": "2024-05-01T17:04:07.526956Z",
     "shell.execute_reply": "2024-05-01T17:04:07.526397Z"
    }
   },
   "outputs": [],
   "source": [
    "def send_to_model(data):\n",
    "    if 'Output' in data.columns:\n",
    "        data = data.drop(columns=['Output'])\n",
    "    data_standardized = scaler.transform(data)\n",
    "    data_standardized_df = pd.DataFrame(data_standardized)\n",
    "    data_4d = padding_zero(data_standardized_df,tool_name,total_params,flag=1)\n",
    "    data_4d_object =  data_4d.to_numpy()\n",
    "    data_4d_list = []\n",
    "    for i in range(len(data_4d_object)):\n",
    "        data_4d_list.append(data_4d_object[i][0])\n",
    "    data_4d_arr = np.array(data_4d_list)\n",
    "    data_4d_tensor = torch.tensor(data_4d_arr,dtype=torch.float)\n",
    "    my_dataset = TensorDataset(data_4d_tensor)\n",
    "    batch_size = 256\n",
    "    my_loader = DataLoader(my_dataset, batch_size=batch_size,num_workers=4)\n",
    "    data_output = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in my_loader:\n",
    "        # 将数据移到指定的设备上（如 CUDA 设备）\n",
    "            batch_data = batch_data[0].to(device)\n",
    "        \n",
    "        # 将数据传递给模型进行推理\n",
    "            batch_output = s1_model(batch_data)\n",
    "            probs = (torch.nn.functional.softmax(batch_output, dim=1))\n",
    "        # 将输出保存起来\n",
    "            data_output += probs\n",
    "    data_output_arr = np.array([output.cpu().numpy()[0] for output in data_output])\n",
    "    data_expectation_out = data_output_arr.mean()\n",
    "    return data_expectation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T17:04:07.536693Z",
     "iopub.status.busy": "2024-05-01T17:04:07.534860Z",
     "iopub.status.idle": "2024-05-01T21:04:34.232365Z",
     "shell.execute_reply": "2024-05-01T21:04:34.231666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31661\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import warnings\n",
    "import itertools\n",
    "# 過濾掉FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "def all_subsets(n_elts):\n",
    "    '''\n",
    "        returns a list of 2^{n_elts} lists\n",
    "        each a different subset of {1, 2,...,n_elts}\n",
    "    '''\n",
    "    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\n",
    "    res = {i : res[i] for i in range(n_elts)}\n",
    "    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\n",
    "    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\n",
    "para_num = 14\n",
    "AUO_coalitions = [np.array([])] + all_subsets(para_num) \n",
    "coalition_estimated_values = {}\n",
    "instance = new_df.iloc[2]\n",
    "#mean_exp = new_df['Output'].mean()\n",
    "flag=0\n",
    "count_n = 1\n",
    "selected_data = new_df.copy()\n",
    "selected_data = selected_data[(selected_data['PUMP_low']<20000) & \n",
    "                              (selected_data['PUMP_high']>20000) & \n",
    "                              (selected_data['VENT_low']<10000) & \n",
    "                              (selected_data['VENT_high']>10000) &\n",
    "                              (selected_data['NH3_TREAT_-RF_FREQ-max']>13800)&\n",
    "                              (selected_data['NH3_TREAT_-RF_FREQ-mean']<13800)\n",
    "                                                            ]\n",
    "print(len(selected_data))\n",
    "sample_df = selected_data.sample(n=1000,random_state=42)\n",
    "instance.to_csv('instance_2.csv',index=True)\n",
    "sample_df.to_csv('background_dataset_2.csv',index=True)\n",
    "mean_exp = sample_df['Output'].mean()\n",
    "for coalition in AUO_coalitions:\n",
    "    synth = sample_df.copy()                   #用copy()才不會去更改到原始的dataframe\n",
    "    if len(coalition)!=0:\n",
    "        #print(synth.iloc[:,coalition],instance[coalition])\n",
    "        synth.iloc[:,coalition] = instance.iloc[coalition]\n",
    "        \n",
    "        '''if len(coalition)==3 and flag==0:\n",
    "            print(instance)\n",
    "            print(synth.head(5))\n",
    "            flag=1'''\n",
    "        #if (2 in coalition and 3 not in coalition):\n",
    "        #    PUMP_high = instance.iloc[2]\n",
    "        #    synth = synth[synth.iloc[:,3]<PUMP_high]\n",
    "            #print('good')\n",
    "            \n",
    "    #if count_n==100:\n",
    "        #print('資料集長度:',len(synth))\n",
    "        #print('feature數:',len(coalition))\n",
    "        #print('資料: ',synth)\n",
    "        #print(coalition)\n",
    "        #count_n = 0\n",
    "\n",
    "    count_n += 1\n",
    "    Exp = send_to_model(synth)\n",
    "    impact = Exp - mean_exp\n",
    "\n",
    "    coalition_estimated_values[str(coalition)] = impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T21:04:34.234813Z",
     "iopub.status.busy": "2024-05-01T21:04:34.234536Z",
     "iopub.status.idle": "2024-05-01T21:04:51.148541Z",
     "shell.execute_reply": "2024-05-01T21:04:51.147874Z"
    }
   },
   "outputs": [],
   "source": [
    "AUOcube = Hypercube(para_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T21:04:51.151144Z",
     "iopub.status.busy": "2024-05-01T21:04:51.150707Z",
     "iopub.status.idle": "2024-05-01T21:04:51.157573Z",
     "shell.execute_reply": "2024-05-01T21:04:51.157033Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "AUOcube.set_vertex_values(coalition_estimated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T21:04:51.160790Z",
     "iopub.status.busy": "2024-05-01T21:04:51.160546Z",
     "iopub.status.idle": "2024-05-01T21:04:51.166426Z",
     "shell.execute_reply": "2024-05-01T21:04:51.165972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_-TACT_TIME_mean              90.000000\n",
      "X_-CONVEYOR_SPEED_mean       4200.000000\n",
      "PUMP_high                   40499.960000\n",
      "PUMP_low                    12198.940000\n",
      "CLN1_over-etching-ratio         0.005368\n",
      "CLN1_EPT_time               10059.000000\n",
      "clean_count                     3.000000\n",
      "EPT_clean_count_ratio        3353.000000\n",
      "NH3_TREAT_-RF_FREQ-max      13948.000000\n",
      "NH3_TREAT_-RF_FREQ-range      418.000000\n",
      "NH3_TREAT_-RF_FREQ-mean     13649.428600\n",
      "NP_3_-MFC_VOL_SIH4-range        1.000000\n",
      "VENT_high                   17061.037500\n",
      "VENT_low                     5707.557143\n",
      "Output                          0.576102\n",
      "Name: 2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T21:04:51.169439Z",
     "iopub.status.busy": "2024-05-01T21:04:51.169227Z",
     "iopub.status.idle": "2024-05-02T10:57:16.653487Z",
     "shell.execute_reply": "2024-05-02T10:57:16.653189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.7655786974583195\n",
      "shapley_value:  0.09862317847932489 residual sum:  552.7565692918788\n",
      "0.09862317847932489\n",
      "X_-TACT_TIME_mean residuals_of_feature 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9992564790088183\n",
      "shapley_value:  -0.025965323940689476 residual sum:  458.56245983431796\n",
      "0.07265785453863541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_-CONVEYOR_SPEED_mean residuals_of_feature 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9912664856695693\n",
      "shapley_value:  -0.016877373771484523 residual sum:  188.08657610967379\n",
      "0.055780480767150885\n",
      "PUMP_high residuals_of_feature 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9864934181624424\n",
      "shapley_value:  -0.026415122822479317 residual sum:  169.20603210410238\n",
      "0.02936535794467157\n",
      "PUMP_low residuals_of_feature 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9818173980357827\n",
      "shapley_value:  -0.019613043293695107 residual sum:  174.60939347028406\n",
      "0.009752314650976462\n",
      "CLN1_over-etching-ratio residuals_of_feature 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9819048962808757\n",
      "shapley_value:  -0.0639941084785518 residual sum:  476.8627744151126\n",
      "-0.05424179382757534\n",
      "CLN1_EPT_time residuals_of_feature 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9406250367508547\n",
      "shapley_value:  -0.004105785748102367 residual sum:  280.17819241913287\n",
      "-0.058347579575677704\n",
      "clean_count residuals_of_feature 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.87071176297915\n",
      "shapley_value:  0.006464340314739804 residual sum:  83.67462629636034\n",
      "-0.0518832392609379\n",
      "EPT_clean_count_ratio residuals_of_feature 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.981797165658508\n",
      "shapley_value:  -0.02083402155460174 residual sum:  108.91352024147356\n",
      "-0.07271726081553964\n",
      "NH3_TREAT_-RF_FREQ-max residuals_of_feature 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9812507169234607\n",
      "shapley_value:  -0.02853168615563992 residual sum:  145.56813939985884\n",
      "-0.10124894697117956\n",
      "NH3_TREAT_-RF_FREQ-range residuals_of_feature 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9872253852367557\n",
      "shapley_value:  -0.008051343082402409 residual sum:  57.285486030178085\n",
      "-0.10930029005358197\n",
      "NH3_TREAT_-RF_FREQ-mean residuals_of_feature 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.9796883084553142\n",
      "shapley_value:  -0.00011466796277219186 residual sum:  0.9390108680178189\n",
      "-0.10941495801635416\n",
      "NP_3_-MFC_VOL_SIH4-range residuals_of_feature 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.972575864075348\n",
      "shapley_value:  -0.010173941501794664 residual sum:  66.55957049339271\n",
      "-0.11958889951814883\n",
      "VENT_high residuals_of_feature 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_sim =  0.49570276980310135\n",
      "shapley_value:  0.019986081029070502 residual sum:  276.8047260613952\n",
      "-0.09960281848907833\n",
      "VENT_low residuals_of_feature 13\n"
     ]
    }
   ],
   "source": [
    "for i  in range(para_num):\n",
    "    AUOcube.trans_to_matrix(feature_i=i)\n",
    "    res = AUOcube.shapley_residuals_in_matrix()\n",
    "    print(new_df.columns[i],'residuals_of_feature',i)\n",
    "    save_json(res,feature_name=params_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T10:57:16.826675Z",
     "iopub.status.busy": "2024-05-02T10:57:16.826012Z",
     "iopub.status.idle": "2024-05-02T10:57:16.862477Z",
     "shell.execute_reply": "2024-05-02T10:57:16.862222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6757052\n"
     ]
    }
   ],
   "source": [
    "print(mean_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T10:57:16.863651Z",
     "iopub.status.busy": "2024-05-02T10:57:16.863550Z",
     "iopub.status.idle": "2024-05-02T10:57:16.865760Z",
     "shell.execute_reply": "2024-05-02T10:57:16.865561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_-TACT_TIME_mean', 'X_-CONVEYOR_SPEED_mean', 'PUMP_high', 'PUMP_low',\n",
       "       'CLN1_over-etching-ratio', 'CLN1_EPT_time', 'clean_count',\n",
       "       'EPT_clean_count_ratio', 'NH3_TREAT_-RF_FREQ-max',\n",
       "       'NH3_TREAT_-RF_FREQ-range', 'NH3_TREAT_-RF_FREQ-mean',\n",
       "       'NP_3_-MFC_VOL_SIH4-range', 'VENT_high', 'VENT_low', 'Output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T10:57:16.866914Z",
     "iopub.status.busy": "2024-05-02T10:57:16.866816Z",
     "iopub.status.idle": "2024-05-02T10:57:18.858432Z",
     "shell.execute_reply": "2024-05-02T10:57:18.855858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  2 18:57:18 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:01:00.0 Off |                  Off |\r\n",
      "|  0%   36C    P8              15W / 480W |   1791MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:07:00.0 Off |                  Off |\r\n",
      "|  0%   39C    P8              20W / 480W |   3359MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1313      G   /usr/lib/xorg/Xorg                            9MiB |\r\n",
      "|    0   N/A  N/A      1678      G   /usr/bin/gnome-shell                          6MiB |\r\n",
      "|    0   N/A  N/A   2866176      C   ...skes/anaconda3/envs/ares/bin/python     1762MiB |\r\n",
      "|    1   N/A  N/A      1313      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "|    1   N/A  N/A    935928      C   .../anaconda3/envs/shap_res/bin/python      830MiB |\r\n",
      "|    1   N/A  N/A    936496      C   .../anaconda3/envs/shap_res/bin/python      830MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shap_res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
