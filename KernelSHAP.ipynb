{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "1. 檢查是不是能透過kernelSHAP得到vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from data_process import read_selected_data, get_y,  split_data, compute_class_weights\n",
    "from dataset import BertDataset\n",
    "from model import BertClassifier\n",
    "from training import train_model\n",
    "from utils import draw_pics, initial_record\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "total_params = 14\n",
    "csv_file_path = '/hcds_vol/private/luffy/GANGAN-master/data/processed_data/v014_stage_1.csv'\n",
    "json_file_path = '/hcds_vol/private/luffy/GANGAN-master/data/controllable_para_v014_14.json'\n",
    "tool_name = 'ASCVD'\n",
    "epochs = 50000\n",
    "lr = 1e-5\n",
    "batch_size = 1024\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "save_folder_name = 'stage-1-param_'+str(total_params)+'-batch_'+str(batch_size)+'-lr_'+str(lr)\n",
    "with open(json_file_path, 'r') as f:\n",
    "    params = json.load(f)\n",
    "    f.close()\n",
    "s1_df = pd.read_csv(csv_file_path)\n",
    "#s1_df.shape\n",
    "all_key = list(params[tool_name]) \n",
    "params_list = []                #取得json檔內的特徵\n",
    "for key in all_key:\n",
    "    all_param = params[tool_name][key]\n",
    "    if(type(all_param) == list):\n",
    "        for param in all_param:\n",
    "             params_list.append(param)\n",
    "    else:\n",
    "        params_list.append(all_param)\n",
    "    \n",
    "# 取得Json檔內包含的特徵\n",
    "s1_df = s1_df[params_list] \n",
    "#print(params)\n",
    "s1_df.head(10)\n",
    "feature_df = s1_df.drop(['DFT_CNT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 8, 2]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(feature_df)\n",
    "nf_df = pd.DataFrame(X_standardized)\n",
    "nf_df\n",
    "param_group = [] # [2,2,4,2]\n",
    "all_key = list(params[tool_name]) # ['EQ', 'PUMP', 'CH', 'VENT', 'y']\n",
    "all_key.remove('y')\n",
    "\n",
    "for key in all_key:\n",
    "    all_value = params[tool_name][key]\n",
    "    param_group.append(len(all_value))\n",
    "param_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_zero(df, tool_name, total_params, flag, params=params): \n",
    "    # 將一維參數matrix擴展為4維\n",
    "    data_arr = df.to_numpy()\n",
    "    result = []\n",
    "    for i in range(len(data_arr)):\n",
    "        arr_index = 0\n",
    "        empty_arr = np.zeros((4,total_params)) # chamber數 * 總參數數量\n",
    "        param_group_cp = param_group.copy()\n",
    "        for j in range(len(empty_arr)):\n",
    "            while(param_group_cp[j] > 0):\n",
    "                empty_arr[j][arr_index] = data_arr[i][arr_index]\n",
    "                param_group_cp[j] -= 1\n",
    "                arr_index += 1\n",
    "        \n",
    "        if(flag == 1): # bert.py使用\n",
    "            result.append(empty_arr)\n",
    "        if(flag == 2): # bert_du.py使用\n",
    "            result.append(empty_arr.tolist())\n",
    "    \n",
    "    if(flag == 1): # bert.py使用\n",
    "        result = pd.DataFrame({'X': [result[i] for i in range(len(result))]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_df_4d = padding_zero(nf_df,tool_name,total_params,flag=1)\n",
    "nf_df_4d_object = nf_df_4d.to_numpy()\n",
    "nf_df_4d_list = []\n",
    "for i in range(len(nf_df_4d_object)):\n",
    "    nf_df_4d_list.append(nf_df_4d_object[i][0])\n",
    "nf_df_4d_arr = np.array(nf_df_4d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "s1_model_path = '/hcds_vol/private/luffy/GANGAN-master/model/predictor/stage_1_checkpoint.pth'\n",
    "s1_model =  torch.load(s1_model_path).to(device)\n",
    "s1_model.eval()\n",
    "nf_df_4d_tensor = torch.tensor(nf_df_4d_arr,dtype=torch.float)\n",
    "dataset = TensorDataset(nf_df_4d_tensor)\n",
    "batch_size = 256\n",
    "loader = DataLoader(dataset, batch_size=batch_size)\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for batch_data in loader:\n",
    "        # 将数据移到指定的设备上（如 CUDA 设备）\n",
    "        batch_data = batch_data[0].to(device)\n",
    "        \n",
    "        # 将数据传递给模型进行推理\n",
    "        batch_output = s1_model(batch_data)\n",
    "        probs = (torch.nn.functional.softmax(batch_output, dim=1))\n",
    "        # 将输出保存起来\n",
    "        outputs += probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_arr = np.array([output.cpu().numpy()[0] for output in outputs])\n",
    "output_df = pd.DataFrame({'Output': output_arr})\n",
    "new_df = pd.concat([feature_df,output_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_model(data):\n",
    "    #if 'Output' in data.columns:\n",
    "         #data = data.drop(columns=['Output'])\n",
    "    data_standardized = scaler.transform(data)\n",
    "    data_standardized_df = pd.DataFrame(data_standardized)\n",
    "    data_4d = padding_zero(data_standardized_df,tool_name,total_params,flag=1)\n",
    "    data_4d_object =  data_4d.to_numpy()\n",
    "    data_4d_list = []\n",
    "    for i in range(len(data_4d_object)):\n",
    "        data_4d_list.append(data_4d_object[i][0])\n",
    "    data_4d_arr = np.array(data_4d_list)\n",
    "    data_4d_tensor = torch.tensor(data_4d_arr,dtype=torch.float)\n",
    "    my_dataset = TensorDataset(data_4d_tensor)\n",
    "    batch_size = 256\n",
    "    my_loader = DataLoader(my_dataset, batch_size=batch_size,num_workers=4)\n",
    "    data_output = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in my_loader:\n",
    "        # 将数据移到指定的设备上（如 CUDA 设备）\n",
    "            batch_data = batch_data[0].to(device)\n",
    "        \n",
    "        # 将数据传递给模型进行推理\n",
    "            batch_output = s1_model(batch_data)\n",
    "            probs = (torch.nn.functional.softmax(batch_output, dim=1))\n",
    "        # 将输出保存起来\n",
    "            data_output += probs\n",
    "    data_output_arr = np.array([output.cpu().numpy()[0] for output in data_output])\n",
    "    #data_expectation_out = data_output_arr.mean()\n",
    "    return data_output_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 1000 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "做堆疊\n",
      "1000\n",
      "[[1.50000000e+02 3.15000000e+03 2.73519833e+04 ... 1.00000000e+00\n",
      "  1.68432882e+04 7.87221111e+03]\n",
      " [1.60000000e+02 2.65000000e+03 5.40493333e+04 ... 1.00000000e+00\n",
      "  1.95210769e+04 8.40490000e+03]\n",
      " [1.50000000e+02 3.15000000e+03 4.13653600e+04 ... 1.00000000e+00\n",
      "  1.49724937e+04 5.65047857e+03]\n",
      " ...\n",
      " [1.40000000e+02 3.15000000e+03 3.68338400e+04 ... 1.00000000e+00\n",
      "  1.59592867e+04 7.13825000e+03]\n",
      " [1.60000000e+02 2.65000000e+03 4.58784200e+04 ... 1.00000000e+00\n",
      "  1.91068385e+04 7.90180000e+03]\n",
      " [1.45000000e+02 3.15000000e+03 5.07670000e+04 ... 1.00000000e+00\n",
      "  1.63849875e+04 7.31258182e+03]]\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n",
      "here7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but StandardScaler was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 13)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import warnings\n",
    "import itertools\n",
    "# 過濾掉FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "def all_subsets(n_elts):\n",
    "    '''\n",
    "        returns a list of 2^{n_elts} lists\n",
    "        each a different subset of {1, 2,...,n_elts}\n",
    "    '''\n",
    "    res = [np.array(list(itertools.combinations(set(range(n_elts)), i))) for i in range(n_elts)]\n",
    "    res = {i : res[i] for i in range(n_elts)}\n",
    "    res[n_elts] = np.array([i for i in range(n_elts)]).reshape(1,-1)\n",
    "    return [res[i][j] for i in range(1,n_elts+1) for j in range(res[i].shape[0])]\n",
    "para_num = 14\n",
    "AUO_coalitions = [np.array([])] + all_subsets(para_num) \n",
    "coalition_estimated_values = {}\n",
    "instance = new_df.iloc[2]\n",
    "#mean_exp = new_df['Output'].mean()\n",
    "flag=0\n",
    "count_n = 1\n",
    "selected_data = new_df.copy()\n",
    "selected_data = selected_data[(selected_data['PUMP_low']<20000) & \n",
    "                              (selected_data['PUMP_high']>20000) & \n",
    "                              (selected_data['VENT_low']<10000) & \n",
    "                              (selected_data['VENT_high']>10000) &\n",
    "                              (selected_data['NH3_TREAT_-RF_FREQ-max']>13800)&\n",
    "                              (selected_data['NH3_TREAT_-RF_FREQ-mean']<13800)\n",
    "                                                            ]\n",
    "sample_df = selected_data.sample(n=1000,random_state=42)\n",
    "print(type(sample_df))\n",
    "mean_exp = sample_df['Output'].mean()\n",
    "sample_df = sample_df.drop(columns=['Output'])\n",
    "instance = instance.drop(labels=['Output'])\n",
    "explainer = shap.KernelExplainer(send_to_model, sample_df)\n",
    "shap_values = explainer.shap_values(instance, nsamples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The waterfall plot requires an `Explanation` object as the `shap_values` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaterfall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hcds_vol/private/luffy/anaconda3/envs/shap_res/lib/python3.9/site-packages/shap/plots/_waterfall.py:58\u001b[0m, in \u001b[0;36mwaterfall\u001b[0;34m(shap_values, max_display, show)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shap_values, Explanation):\n\u001b[1;32m     54\u001b[0m     emsg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe waterfall plot requires an `Explanation` object as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shap_values` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(emsg)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# make sure we only have a single explanation to plot\u001b[39;00m\n\u001b[1;32m     61\u001b[0m sv_shape \u001b[38;5;241m=\u001b[39m shap_values\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: The waterfall plot requires an `Explanation` object as the `shap_values` argument."
     ]
    }
   ],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values = [ 0.09619054 -0.02663675 -0.01717055 -0.02686515 -0.02065319 -0.06259205\n",
      " -0.00205657  0.0096463  -0.01979932 -0.02788637 -0.00862422 -0.00307333\n",
      " -0.00796304  0.01788066]\n"
     ]
    }
   ],
   "source": [
    "print(\"shap_values =\", shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_-TACT_TIME_mean', 'X_-CONVEYOR_SPEED_mean', 'PUMP_high', 'PUMP_low', 'CLN1_over-etching-ratio', 'CLN1_EPT_time', 'clean_count', 'EPT_clean_count_ratio', 'NH3_TREAT_-RF_FREQ-max', 'NH3_TREAT_-RF_FREQ-range', 'NH3_TREAT_-RF_FREQ-mean', 'NP_3_-MFC_VOL_SIH4-range', 'VENT_high', 'VENT_low', 'DFT_CNT']\n"
     ]
    }
   ],
   "source": [
    "print(params_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shap_res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
